{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b34a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import torch\n",
    "import lightning as L\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# my model\n",
    "from model.basicNN import L_NN_ID as iden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a360487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setting\n",
    "model = iden(in_feature=4, h1=8, h2=9, out_feature=3)\n",
    "torch.manual_seed = 81\n",
    "epochs = 300\n",
    "log_every_n_step = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "853d771c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "# import and modify data with pandas\n",
    "directory = \"data\\iris\\iris.csv\"  # can use url\n",
    "df = pd.read_csv(directory, delimiter=\",\")\n",
    "print(df.head())\n",
    "\n",
    "no_rep_variety = df[\"variety\"].drop_duplicates()  # retrive none duplicated items\n",
    "verbal_to_code = {\n",
    "    verbal: i for i, verbal in enumerate(no_rep_variety)\n",
    "}  # create verbal to code dictionary\n",
    "df[\"variety\"] = df[\"variety\"].map(verbal_to_code)  # map/replace verbal with int\n",
    "\n",
    "X = df.drop(\"variety\", axis=1)  # axis=1 =remove column, axis=0 = remove 1st row/index\n",
    "y = df[\"variety\"]\n",
    "# assigning inputs and labels and convert to tensor\n",
    "input = torch.FloatTensor(X.values)\n",
    "label = torch.LongTensor(y.values)  ##longTensor = int64\n",
    "\n",
    "# train test split\n",
    "train_input, test_input, train_label, test_label = train_test_split(\n",
    "    input, label, test_size=0.2, random_state=81\n",
    ")\n",
    "train_dataset = TensorDataset(train_input, train_label)\n",
    "test_dataset = TensorDataset(test_input, test_label)\n",
    "# dataloader\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "298bbc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Finding best initial lr:  78%|███████▊  | 78/100 [00:00<00:00, 135.12it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:00<00:00, 111.27it/s]\n",
      "Learning rate set to 0.06025595860743578\n",
      "Restoring states from the checkpoint path at d:\\Work repository\\NN_test_build\\.lr_find_2333803e-1ea3-4c44-b5db-08ef2a5d00ca.ckpt\n",
      "Restored all states from the checkpoint at d:\\Work repository\\NN_test_build\\.lr_find_2333803e-1ea3-4c44-b5db-08ef2a5d00ca.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type   | Params | Mode \n",
      "----------------------------------------\n",
      "0 | fc1  | Linear | 40     | train\n",
      "1 | fc2  | Linear | 81     | train\n",
      "2 | out  | Linear | 30     | train\n",
      "----------------------------------------\n",
      "151       Trainable params\n",
      "0         Non-trainable params\n",
      "151       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_find() suggest 0.060256 for the learning rate.\n",
      "Epoch 299: 100%|██████████| 4/4 [00:00<00:00, 214.80it/s, v_num=4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 4/4 [00:00<00:00, 155.22it/s, v_num=4]\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=epochs, log_every_n_steps=log_every_n_step)\n",
    "# learning rate finder\n",
    "tuner = L.pytorch.tuner.Tuner(trainer)\n",
    "lr_find_results = tuner.lr_find(\n",
    "    model,\n",
    "    train_dataloaders=train_loader,\n",
    "    min_lr=0.01,\n",
    "    max_lr=1.0,\n",
    "    early_stop_threshold=None,\n",
    ")\n",
    "new_lr = lr_find_results.suggestion()\n",
    "model.learning_rate = new_lr\n",
    "print(f\"lr_find() suggest {new_lr:5f} for the learning rate.\")\n",
    "# train to fit\n",
    "trainer.fit(model, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f4c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b57a27ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8480), started 0:02:03 ago. (Use '!kill 8480' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6d54b0f8158006f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6d54b0f8158006f\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tensorboard loss result\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b7ba4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at d:\\Work repository\\NN_test_build\\lightning_logs\\version_4\\checkpoints\\epoch=299-step=1200.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at d:\\Work repository\\NN_test_build\\lightning_logs\\version_4\\checkpoints\\epoch=299-step=1200.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.37it/s]\n",
      "1.) tensor([-72.5319,   2.3768,  10.4118]) \t 2 \t 2\n",
      "2.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "3.) tensor([-66.5345,   2.3664,   9.2107]) \t 2 \t 2\n",
      "4.) tensor([-26.0430,   3.8171,  -2.9796]) \t 1 \t 1\n",
      "5.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "6.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "7.) tensor([-29.7548,   3.6648,  -1.8109]) \t 1 \t 1\n",
      "8.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "9.) tensor([-57.9655,   2.5071,   7.0714]) \t 2 \t 2\n",
      "10.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "11.) tensor([-11.6837,   4.0228,  -6.7199]) \t 1 \t 1\n",
      "12.) tensor([-4.0109,  4.1071, -8.6662]) \t 1 \t 1\n",
      "13.) tensor([-93.4462,   2.4130,  14.6002]) \t 2 \t 2\n",
      "14.) tensor([-49.4859,   2.8551,   4.4015]) \t 2 \t 2\n",
      "15.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "16.) tensor([-65.9147,   2.3653,   9.0866]) \t 2 \t 2\n",
      "17.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "18.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "19.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "20.) tensor([-23.0240,   3.8983,  -3.8433]) \t 1 \t 1\n",
      "21.) tensor([-11.7836,   4.0217,  -6.6946]) \t 1 \t 1\n",
      "22.) tensor([-17.0231,   3.9642,  -5.3655]) \t 1 \t 1\n",
      "23.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "24.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "25.) tensor([-18.5837,   3.9471,  -4.9696]) \t 1 \t 1\n",
      "26.) tensor([-21.6345,   3.9136,  -4.1958]) \t 1 \t 1\n",
      "27.) tensor([ 0.7869,  4.1597, -9.8833]) \t 1 \t 1\n",
      "28.) tensor([-76.8932,   2.3843,  11.2852]) \t 2 \t 2\n",
      "29.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "30.) tensor([ 12.0788,   4.2838, -12.7480]) \t 0 \t 0\n",
      "30 / 30 are correct\n",
      "accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "with torch.no_grad():\n",
    "    best_ckpt = trainer.checkpoint_callback.best_model_path\n",
    "    tester = L.Trainer()\n",
    "    tester.test(model, dataloaders=test_loader, ckpt_path=best_ckpt)\n",
    "    correct = 0\n",
    "    for i, data in enumerate(test_input):\n",
    "        test_res = torch.tensor(model.forward(test_input))\n",
    "        test_res_arg = torch.argmax(test_res, dim=1, keepdim=False)\n",
    "        print(f\"{i + 1}.) {test_res[i]} \\t {test_res_arg[i]} \\t {test_label[i]}\")\n",
    "        if test_res_arg[i] == test_label[i]:\n",
    "            correct += 1\n",
    "        right = model.calculate_accuracy(test_res, test_label)\n",
    "        right\n",
    "    print(f\"{correct} / {len(test_label)} are correct\")\n",
    "    print(f\"accuracy = {correct / len(test_label)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f49cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving parameters\n",
    "torch.save(model.state_dict(), \"trained_parameters\\l_id_iris.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b34a37e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the iris types are:\n",
      "1.) Setosa\n",
      "2.) Versicolor\n",
      "3.) Virginica\n"
     ]
    }
   ],
   "source": [
    "# region Identify by model\n",
    "# load model and parameters\n",
    "loaded_model = iden(in_feature=4, h1=8, h2=9, out_feature=3)\n",
    "loaded_model.load_state_dict(torch.load(\"trained_parameters\\l_id_iris.pt\"))\n",
    "\n",
    "# identify\n",
    "with torch.no_grad():\n",
    "    sus_input = torch.tensor(\n",
    "        [[5, 3.5, 1.6, 0.6], [5.1, 2.5, 3, 1.1], [6.9, 3.2, 5.7, 2.3]]\n",
    "    )\n",
    "    print(\"the iris types are:\")\n",
    "    for i, data in enumerate(sus_input):\n",
    "        sus_res = loaded_model.forward(sus_input).clone().detach()\n",
    "        sus_res_arg = torch.argmax(sus_res, dim=1, keepdim=False)\n",
    "        if sus_res_arg[i] == 0:\n",
    "            sus = \"Setosa\"\n",
    "        elif sus_res_arg[i] == 1:\n",
    "            sus = \"Versicolor\"\n",
    "        else:\n",
    "            sus = \"Virginica\"\n",
    "        print(f\"{i + 1}.) {sus}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
